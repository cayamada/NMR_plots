{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmpkJt9MtPd0IgfJBLuqHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cayamada/NMR_plots/blob/main/Plots_intensity_decay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GRDDu41h4GT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Suponha que seus arquivos se chamem 'dataset1.csv' e 'dataset2.csv'\n",
        "file_id = 'comparison_Gd_2.csv'\n",
        "file_id2 = 'comparison__Ab_Gd_2.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "df1 = pd.read_csv(file_id)\n",
        "df2 = pd.read_csv(file_id2)\n",
        "\n",
        "# Excluir a 10ª coluna (se necessário) - adapte conforme necessário\n",
        "df1 = df1.drop(df1.columns[-1], axis=1)\n",
        "df2 = df2.drop(df2.columns[-1], axis=1)\n",
        "\n",
        "# Extrair o número da primeira coluna e converter para inteiro\n",
        "df1['Numero'] = df1['Dim 1'].str.extract('(\\d+)').astype(int)\n",
        "df2['Numero'] = df2['Dim 1'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Ordenar os DataFrames com base no número extraído\n",
        "df1 = df1.sort_values(by='Numero')\n",
        "df2 = df2.sort_values(by='Numero')\n",
        "\n",
        "# Remover a coluna auxiliar 'Numero' se não for mais necessária\n",
        "#df1 = df1.drop(columns='Numero')\n",
        "#df2 = df2.drop(columns='Numero')\n",
        "\n",
        "# Combinar DataFrames apenas nos resíduos comuns\n",
        "common_residues = pd.merge(df1, df2, on='Dim 1', how='inner')\n",
        "\n",
        "# Defina as colunas que representam as concentrações de Gd (0.000, 1.000, 1.500, 2.000, 2.500)\n",
        "concentration_columns = ['1.000', '1.500', '2.000', '2.500']\n",
        "\n",
        "# Função exponencial para ajuste\n",
        "def exponential_func(x, a, b):\n",
        "    return a * np.exp(b * x)\n",
        "\n",
        "# Função para calcular a diferença nas inclinações e interceptações\n",
        "def compare_trendlines(params1, params2):\n",
        "    slope_diff = params2[1] - params1[1]\n",
        "    intercept_diff = params2[0] - params1[0]\n",
        "    return slope_diff, intercept_diff\n",
        "\n",
        "# Iterar pelos resíduos em \"Dim 1\" e plotar os valores de intensidade em função das concentrações\n",
        "for index, row in common_residues.iterrows():\n",
        "    residue = row['Dim 1']  # O resíduo em \"Dim 1\"\n",
        "\n",
        "    # Obter os rótulos corretos para as colunas de intensidade\n",
        "    intensity_columns1 = [col + '_x' for col in concentration_columns]\n",
        "    intensity_columns2 = [col + '_y' for col in concentration_columns]\n",
        "\n",
        "    intensity_values1 = row[intensity_columns1].astype(float)  # Valores de intensidade do primeiro DataFrame\n",
        "    intensity_values2 = row[intensity_columns2].astype(float)  # Valores de intensidade do segundo DataFrame\n",
        "\n",
        "    # Ajustar a linha de tendência exponencial usando curve_fit\n",
        "    params1, _ = curve_fit(exponential_func, np.arange(len(concentration_columns)), intensity_values1)\n",
        "    params2, _ = curve_fit(exponential_func, np.arange(len(concentration_columns)), intensity_values2)\n",
        "\n",
        "    # Calcular os valores da linha de tendência exponencial\n",
        "    trend_values1 = exponential_func(np.arange(len(concentration_columns)), *params1)\n",
        "    trend_values2 = exponential_func(np.arange(len(concentration_columns)), *params2)\n",
        "\n",
        "    # Comparar as linhas de tendência\n",
        "    slope_diff, intercept_diff = compare_trendlines(params1, params2)\n",
        "\n",
        "    # Configurar o gráfico de linhas com as linhas de tendência exponenciais\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(concentration_columns, intensity_values1, marker='o', color='blue', linestyle='-', label='Ptn')\n",
        "    plt.plot(concentration_columns, intensity_values2, marker='s', color='red', linestyle='-', label='Ptn + Ab')\n",
        "    plt.plot(concentration_columns, trend_values1, linestyle='--', color='blue', alpha=0.5)\n",
        "    plt.plot(concentration_columns, trend_values2, linestyle='--', color='red', alpha=0.5)\n",
        "\n",
        "\n",
        "    # Set the background color to light gray\n",
        "    sns.set_style(\"whitegrid\", {\"axes.facecolor\": \".90\"})\n",
        "\n",
        "    # add a gray grid to the plot\n",
        "    plt.grid(color='white', linestyle='-', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Concentração de Gd (µM)')\n",
        "    plt.ylabel('Intensidade do Sinal')\n",
        "    plt.title(residue)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Set the DPI to 300\n",
        "    plt.rcParams['figure.dpi'] = 300\n",
        "\n",
        "    # save the plot\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/My Drive/CCPNMR/Gd/Plots/' + residue + '.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    # Exibir o gráfico no notebook\n",
        "    plt.show()\n",
        "\n",
        "# Lista para armazenar todos os resíduos com suas diferenças nas inclinações\n",
        "all_residues_with_slope_diff = []\n",
        "\n",
        "# Iterar pelos resíduos em \"Dim 1\" e calcular a diferença na inclinação\n",
        "for index, row in common_residues.iterrows():\n",
        "    residue = row['Dim 1']  # O resíduo em \"Dim 1\"\n",
        "\n",
        "    # Obter os rótulos corretos para as colunas de intensidade\n",
        "    intensity_columns1 = [col + '_x' for col in concentration_columns]\n",
        "    intensity_columns2 = [col + '_y' for col in concentration_columns]\n",
        "\n",
        "    intensity_values1 = row[intensity_columns1].astype(float)  # Valores de intensidade do primeiro DataFrame\n",
        "    intensity_values2 = row[intensity_columns2].astype(float)  # Valores de intensidade do segundo DataFrame\n",
        "\n",
        "    # Ajustar a linha de tendência exponencial usando curve_fit\n",
        "    params1, _ = curve_fit(exponential_func, np.arange(len(concentration_columns)), intensity_values1)\n",
        "    params2, _ = curve_fit(exponential_func, np.arange(len(concentration_columns)), intensity_values2)\n",
        "\n",
        "    # Calcular a diferença nas inclinações\n",
        "    slope_diff, intercept_diff = compare_trendlines(params1, params2)\n",
        "\n",
        "    # Armazenar os resultados na lista\n",
        "    all_residues_with_slope_diff.append({\n",
        "        'Residue': residue,\n",
        "        'Slope_Diff': slope_diff,\n",
        "        'Intercept_Diff': intercept_diff\n",
        "    })\n",
        "\n",
        "# Criar um DataFrame com todos os resíduos e diferenças nas inclinações\n",
        "df_all_slope_diff = pd.DataFrame(all_residues_with_slope_diff)\n",
        "\n",
        "# Caminho para a pasta no Google Drive\n",
        "google_drive_path = '/content/drive/MyDrive/CCPNMR/Gd/'\n",
        "\n",
        "# Nome do arquivo CSV\n",
        "csv_filename = 'all_residues_with_slope_diff.csv'\n",
        "\n",
        "# Caminho completo para o arquivo CSV\n",
        "csv_path = google_drive_path + csv_filename\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "df_all_slope_diff.to_csv(csv_path, index=False)\n",
        "\n",
        "# Exibir mensagem informando onde o arquivo foi salvo\n",
        "print(f'O arquivo foi salvo em: {csv_path}')"
      ]
    }
  ]
}